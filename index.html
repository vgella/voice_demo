<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Voice Agent Demo</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <style>
        :root {
            color-scheme: light dark;
            font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
        }
        body {
            margin: 0;
            padding: 24px;
            background: #0f172a;
            color: #e2e8f0;
        }
        h1 {
            margin-top: 0;
            font-size: 1.6rem;
        }
        .panel {
            background: rgba(15, 23, 42, 0.85);
            border: 1px solid rgba(148, 163, 184, 0.3);
            border-radius: 12px;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto 20px auto;
            box-shadow: 0 18px 45px rgba(15, 23, 42, 0.45);
        }
        label {
            display: block;
            margin-bottom: 4px;
            font-weight: 500;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px 12px;
            border-radius: 8px;
            border: 1px solid rgba(148, 163, 184, 0.35);
            background: rgba(15, 23, 42, 0.6);
            color: inherit;
            font-size: 1rem;
            margin-bottom: 12px;
        }
        button {
            cursor: pointer;
            border: none;
            border-radius: 24px;
            padding: 10px 18px;
            margin-right: 10px;
            margin-bottom: 10px;
            font-size: 0.95rem;
            transition: transform 0.15s ease, opacity 0.2s ease;
            background: linear-gradient(135deg, #38bdf8, #0ea5e9);
            color: #0f172a;
            font-weight: 600;
        }
        button.secondary {
            background: transparent;
            color: #e2e8f0;
            border: 1px solid rgba(148, 163, 184, 0.4);
        }
        button:disabled {
            opacity: 0.45;
            cursor: not-allowed;
        }
        button:not(:disabled):hover {
            transform: translateY(-1px);
        }
        #log {
            max-height: 380px;
            overflow-y: auto;
            padding-right: 8px;
        }
        .message {
            margin-bottom: 14px;
            padding: 12px 14px;
            border-radius: 10px;
            line-height: 1.4;
            background: rgba(30, 41, 59, 0.7);
        }
        .message.user {
            border-left: 3px solid #38bdf8;
        }
        .message.agent {
            border-left: 3px solid #a855f7;
        }
        .meta {
            font-size: 0.8rem;
            opacity: 0.7;
            margin-top: 6px;
        }
        #status {
            font-size: 0.9rem;
            margin-top: 12px;
            opacity: 0.8;
        }
        audio {
            width: 100%;
            margin-top: 6px;
        }
        .small-note {
            font-size: 0.8rem;
            opacity: 0.7;
        }
        @media (max-width: 600px) {
            body {
                padding: 16px;
            }
            .panel {
                padding: 16px;
            }
        }
    </style>
</head>
<body>
<div class="panel">
    <h1>Voice Agent Browser Demo</h1>
    <div id="sessionInfo" class="small-note"></div>
    <p>
        Use your Windows microphone to send a message to the running voice agent.
        This page records audio in the browser and sends it to the server for transcription.
    </p>
    <label for="serverUrl">Voice agent URL</label>
    <input id="serverUrl" type="text" data-default-url="/voice/conversation" autocomplete="off">
    <div>
        <button id="listenBtn">ðŸŽ¤ Start Listening</button>
        <button id="stopBtn" class="secondary">Stop Listening</button>
        <button id="sendBtn" class="secondary">Send Typed Message</button>
    </div>
    <input id="textInput" type="text" placeholder="...or type your question here">
    <div id="status">Status: Idle</div>
</div>

<div class="panel">
    <h2>Conversation</h2>
    <div id="log"></div>
    <div id="latency" class="small-note"></div>
</div>

<script>
    const listenBtn = document.getElementById('listenBtn');
    const stopBtn = document.getElementById('stopBtn');
    const sendBtn = document.getElementById('sendBtn');
    const statusEl = document.getElementById('status');
    const logEl = document.getElementById('log');
    const textInput = document.getElementById('textInput');
    const serverUrlInput = document.getElementById('serverUrl');
    const latencyEl = document.getElementById('latency');
    const sessionInfoEl = document.getElementById('sessionInfo');

    const DEFAULT_SERVER_URL = window.VOICE_AGENT_URL
        || localStorage.getItem('voiceAgentServerUrl')
        || serverUrlInput.dataset.defaultUrl;
    serverUrlInput.value = DEFAULT_SERVER_URL;

    serverUrlInput.addEventListener('change', () => {
        try {
            localStorage.setItem('voiceAgentServerUrl', serverUrlInput.value.trim());
        } catch (err) {
            console.warn('Failed to persist server URL', err);
        }
    });

    let listeningArmed = false;
    let micAccessGranted = false;
    let mediaRecorder = null;
    let recordingActive = false;
    let recordedChunks = [];
    let lastRecorderMime = 'audio/webm';

    let micStream = null;
    let micStreamReadyPromise = null;
    let streamingMessageEl = null;
    let streamingTextBuffer = '';
    let playbackController = null;
    let playbackPending = false;
    let shouldRearmAfterPlayback = false;
    let lastPlaybackEndedAt = 0;
    let streamedAudioChunks = [];
    let streamedAudioFormat = 'mp3';

    const PLAYBACK_COOLDOWN_MS = 350;

    function loadOrInitUserId() {
        const storageKey = 'voiceAgentUserId';
        const stored = localStorage.getItem(storageKey);
        if (stored) {
            return stored;
        }
        const token = crypto.randomUUID().split('-')[0];
        const generated = `VOICETEST-${token}`;
        localStorage.setItem(storageKey, generated);
        return generated;
    }

    const userId = loadOrInitUserId();
    const threadId = crypto.randomUUID();
    sessionInfoEl.textContent = `Session ID: ${userId}`;
    let currentTurnMetrics = {
        preambleLatency: null,
        finalLatency: null,
    };

    function updateStatus(text) {
        statusEl.textContent = text;
    }

    function resetTurnMetrics() {
        currentTurnMetrics = {
            preambleLatency: null,
            finalLatency: null,
        };
        latencyEl.textContent = '';
    }

    function applyTurnMetrics() {
        const parts = [];
        if (typeof currentTurnMetrics.preambleLatency === 'number') {
            parts.push(`Preamble: ${Math.round(currentTurnMetrics.preambleLatency)} ms`);
        }
        if (typeof currentTurnMetrics.finalLatency === 'number') {
            parts.push(`Full response: ${Math.round(currentTurnMetrics.finalLatency)} ms`);
        }
        latencyEl.textContent = parts.join(' â€¢ ');
    }

    async function ensureMicPipeline() {
        if (micAccessGranted) {
            return true;
        }
        if (micStreamReadyPromise) {
            try {
                await micStreamReadyPromise;
                return micAccessGranted;
            } catch {
                return false;
            }
        }
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            updateStatus('Status: Microphone not supported in this browser.');
            return false;
        }

        micStreamReadyPromise = (async () => {
            try {
                micStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true,
                    }
                });

                micAccessGranted = true;
                console.log('[DEBUG] Microphone pipeline initialized');
            } catch (err) {
                micAccessGranted = false;
                micStream = null;
                console.error('Microphone permission error', err);
                updateStatus('Status: Microphone permission denied');
                throw err;
            }
        })();

        try {
            await micStreamReadyPromise;
            return micAccessGranted;
        } catch {
            micStreamReadyPromise = null;
            return false;
        }
    }

    function armListening() {
        listeningArmed = true;
        updateStatus('Status: Waiting for speech...');
        listenBtn.disabled = true;
        stopBtn.disabled = false;
    }

    function disarmListening() {
        listeningArmed = false;
        stopRecording();
        updateStatus('Status: Idle');
        listenBtn.disabled = false;
        stopBtn.disabled = true;
    }

    function pickRecorderMimeType() {
        if (!window.MediaRecorder) {
            return '';
        }
        const candidates = [
            'audio/webm;codecs=opus',
            'audio/ogg;codecs=opus',
            'audio/webm',
            'audio/ogg',
        ];
        for (const candidate of candidates) {
            if (MediaRecorder.isTypeSupported(candidate)) {
                return candidate;
            }
        }
        return '';
    }

    function startRecording() {
        if (!micStream || recordingActive) {
            return;
        }
        const mimeType = pickRecorderMimeType();
        recordedChunks = [];
        lastRecorderMime = mimeType || 'audio/webm';
        try {
            mediaRecorder = mimeType
                ? new MediaRecorder(micStream, { mimeType })
                : new MediaRecorder(micStream);
        } catch (err) {
            console.error('Failed to start recorder', err);
            updateStatus('Status: Recorder failed to start');
            return;
        }

        mediaRecorder.ondataavailable = (event) => {
            if (event.data && event.data.size > 0) {
                recordedChunks.push(event.data);
            }
        };

        mediaRecorder.onstop = async () => {
            recordingActive = false;
            const blob = new Blob(recordedChunks, { type: lastRecorderMime });
            if (blob.size === 0) {
                updateStatus('Status: No audio captured');
                listenBtn.disabled = false;
                stopBtn.disabled = true;
                return;
            }
            await sendAudioToAgent(blob, lastRecorderMime);
        };

        mediaRecorder.start();
        recordingActive = true;
        updateStatus('Status: Recording...');
        listenBtn.disabled = true;
        stopBtn.disabled = false;
    }

    function stopRecording() {
        if (mediaRecorder && recordingActive) {
            try {
                mediaRecorder.stop();
            } catch (err) {
                console.warn('mediaRecorder.stop error', err);
            }
        }
    }

    async function startListening() {
        if (!window.MediaRecorder) {
            listenBtn.disabled = true;
            stopBtn.disabled = true;
            updateStatus('Status: MediaRecorder not supported in this browser.');
            return;
        }
        updateStatus('Status: Initializing microphone...');
        const ready = await ensureMicPipeline();
        if (!ready) {
            listenBtn.disabled = false;
            stopBtn.disabled = true;
            return;
        }
        armListening();
        startRecording();
    }

    function stopListening() {
        disarmListening();
        playbackPending = false;
        shouldRearmAfterPlayback = false;
        stopRecording();
    }

    function pauseListeningForPlayback() {
        if (!micAccessGranted) {
            return;
        }
        shouldRearmAfterPlayback = listeningArmed;
        playbackPending = true;
        listeningArmed = false;
        stopRecording();
        updateStatus('Status: Playing response...');
        listenBtn.disabled = true;
        stopBtn.disabled = true;
    }

    function resumeListeningAfterPlayback() {
        playbackPending = false;
        lastPlaybackEndedAt = performance.now();
        if (shouldRearmAfterPlayback) {
            setTimeout(() => {
                shouldRearmAfterPlayback = false;
                armListening();
                startRecording();
            }, PLAYBACK_COOLDOWN_MS);
        } else {
            updateStatus('Status: Idle');
            listenBtn.disabled = false;
            stopBtn.disabled = true;
        }
    }

    stopBtn.disabled = true;

    listenBtn.addEventListener('click', () => {
        startListening();
    });

    stopBtn.addEventListener('click', () => {
        stopListening();
    });

    sendBtn.addEventListener('click', () => {
        const message = textInput.value.trim();
        if (!message) {
            return;
        }
        appendMessage('user', message);
        sendToAgent(message);
        textInput.value = '';
    });

    textInput.addEventListener('keydown', (event) => {
        if (event.key === 'Enter') {
            sendBtn.click();
        }
    });

    async function sendToAgent(message) {
        const endpoint = (serverUrlInput.value || '').trim() || serverUrlInput.dataset.defaultUrl;
        serverUrlInput.value = endpoint;
        try {
            localStorage.setItem('voiceAgentServerUrl', endpoint);
        } catch (err) {
            console.warn('Failed to persist server URL', err);
        }
        const requestBody = {
            user_id: userId,
            thread_id: threadId,
            rooftop_id: '6',
            message,
        };

        try {
            resetTurnMetrics();
            updateStatus('Status: Contacting voice agent...');
            console.log('[DEBUG] sending to agent:', message);

            const response = await fetch(endpoint, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(requestBody),
            });

            if (!response.ok) {
                const text = await response.text();
                throw new Error(`HTTP ${response.status}: ${text}`);
            }

            const contentType = response.headers.get('content-type') || '';
            if (contentType.includes('application/json')) {
                updateStatus('Status: Received response...');
                const payload = await response.json();
                handleNonStreamingResponse(payload);
            } else {
                updateStatus('Status: Streaming response...');
                const reader = response.body.getReader();
                const decoder = new TextDecoder('utf-8');
                let buffer = '';

                while (true) {
                    const { value, done } = await reader.read();
                    if (done) break;

                    buffer += decoder.decode(value, { stream: true });

                    let newlineIndex;
                    while ((newlineIndex = buffer.indexOf('\n')) !== -1) {
                        const rawLine = buffer.slice(0, newlineIndex).trim();
                        buffer = buffer.slice(newlineIndex + 1);
                        if (!rawLine) {
                            continue;
                        }
                        let event;
                        try {
                            event = JSON.parse(rawLine);
                        } catch (err) {
                            console.warn('Failed to parse stream chunk', err, rawLine);
                            continue;
                        }
                        handleStreamEvent(event);
                    }
                }
            }

            updateStatus(listeningArmed ? 'Status: Waiting for speech...' : 'Status: Ready');
        } catch (err) {
            console.error(err);
            statusEl.textContent = `Status: Error - ${err.message}`;
            appendMessage('agent', 'I hit a snag reaching the service. Try again in a moment.');
        }
    }

    async function sendAudioToAgent(blob, mimeType) {
        const endpoint = (serverUrlInput.value || '').trim() || serverUrlInput.dataset.defaultUrl;
        serverUrlInput.value = endpoint;
        try {
            localStorage.setItem('voiceAgentServerUrl', endpoint);
        } catch (err) {
            console.warn('Failed to persist server URL', err);
        }

        const formData = new FormData();
        formData.append('user_id', userId);
        formData.append('thread_id', threadId);
        formData.append('rooftop_id', '6');
        const ext = mimeType && mimeType.includes('ogg') ? 'ogg' : 'webm';
        formData.append('audio', blob, `audio.${ext}`);

        try {
            resetTurnMetrics();
            updateStatus('Status: Contacting voice agent...');
            console.log('[DEBUG] sending audio to agent size:', blob.size);

            const response = await fetch(endpoint, {
                method: 'POST',
                body: formData,
            });

            if (!response.ok) {
                const text = await response.text();
                throw new Error(`HTTP ${response.status}: ${text}`);
            }

            const payload = await response.json();
            if (payload && payload.transcript) {
                appendMessage('user', payload.transcript);
            }
            handleNonStreamingResponse(payload);

            updateStatus(listeningArmed ? 'Status: Waiting for speech...' : 'Status: Ready');
        } catch (err) {
            console.error(err);
            statusEl.textContent = `Status: Error - ${err.message}`;
            appendMessage('agent', 'I hit a snag reaching the service. Try again in a moment.');
        }
    }

    function appendMessage(role, text, label = null) {
        const item = document.createElement('div');
        item.className = `message ${role}`;
        const title = label ? `<strong>${label}:</strong> ` : '';
        item.innerHTML = `${title}${escapeHtml(text)}`;
        logEl.appendChild(item);
        logEl.scrollTop = logEl.scrollHeight;
        return item;
    }

    let audioQueue = Promise.resolve();

    function concatByteArrays(chunks) {
        const total = chunks.reduce((sum, c) => sum + c.byteLength, 0);
        const merged = new Uint8Array(total);
        let offset = 0;
        for (const c of chunks) {
            merged.set(new Uint8Array(c), offset);
            offset += c.byteLength;
        }
        return merged;
    }

    function playAudioSegment(segment, delayFinal = false) {
        if (!segment) return;
        const chunkList = Array.isArray(segment.chunks) && segment.chunks.length
            ? [...segment.chunks]
            : (segment.base64 ? [segment.base64] : []);
        if (!chunkList.length) return;

        audioQueue = audioQueue.then(() => new Promise((resolve) => {
            playbackPending = true;
            pauseListeningForPlayback();

            const playNext = (index) => {
                if (index >= chunkList.length) {
                    resumeListeningAfterPlayback();
                    playbackController = null;
                    resolve();
                    return;
                }

                try {
                    const binary = atob(chunkList[index]);
                    const buffer = new Uint8Array(binary.length);
                    for (let i = 0; i < binary.length; i += 1) {
                        buffer[i] = binary.charCodeAt(i);
                    }
                    const blob = new Blob([buffer], { type: `audio/${segment.format || 'mp3'}` });
                    const url = URL.createObjectURL(blob);
                    const audio = new Audio(url);
                    let cancelled = false;

                    playbackPending = false;
                    playbackController = {
                        abort() {
                            if (cancelled) return;
                            cancelled = true;
                            try {
                                audio.pause();
                            } catch (err) {
                                /* ignore */
                            }
                            URL.revokeObjectURL(url);
                            resumeListeningAfterPlayback();
                            playbackController = null;
                            resolve();
                        }
                    };

                    const startPlayback = () => audio.play().catch((err) => {
                        console.warn('Failed to play audio chunk', err);
                        URL.revokeObjectURL(url);
                        playbackController = null;
                        playNext(index + 1);
                    });

                    audio.onended = () => {
                        URL.revokeObjectURL(url);
                        if (cancelled) {
                            playbackController = null;
                            return;
                        }
                        playNext(index + 1);
                    };
                    audio.onerror = () => {
                        URL.revokeObjectURL(url);
                        playbackController = null;
                        playNext(index + 1);
                    };

                    if (delayFinal && index === 0) {
                        setTimeout(startPlayback, 450);
                    } else {
                        startPlayback();
                    }
                } catch (err) {
                    console.warn('Failed to decode audio chunk', err);
                    playNext(index + 1);
                }
            };

            playNext(0);
        }));
    }
    function stopCurrentPlayback() {
        if (playbackController) {
            const controller = playbackController;
            playbackController = null;
            controller.abort();
        }
    }

    function handleStreamEvent(event) {
        if (!event || typeof event !== 'object') {
            return;
        }

        switch (event.type) {
            case 'session':
                console.log('[DEBUG] Stream session', event.user_id, event.thread_id);
                break;
            case 'error':
                appendMessage('agent', 'I hit a snag finishing that responseâ€”mind giving me just a second and trying again?');
                updateStatus('Status: Error encountered');
                break;
            case 'preamble_text':
                if (event.message) {
                    appendMessage('agent', event.message, 'Preamble');
                }
                if (event.metadata && typeof event.metadata.latency_ms === 'number') {
                    currentTurnMetrics.preambleLatency = event.metadata.latency_ms;
                    applyTurnMetrics();
                }
                break;
            case 'preamble_audio':
                if (event.audio && event.audio.b64) {
                    playAudioSegment({
                        format: event.audio.format || 'mp3',
                        chunks: [event.audio.b64],
                    });
                }
                break;
            case 'final_text': {
                const response = event.response || {};
                streamingTextBuffer = '';
                streamingMessageEl = null;
                if (event.metadata && typeof event.metadata.orchestration_latency_ms === 'number') {
                    currentTurnMetrics.finalLatency = event.metadata.orchestration_latency_ms;
                    applyTurnMetrics();
                }
                break;
            }
            case 'final_audio_text': {
                const text = typeof event.text === 'string' ? event.text.trim() : '';
                if (!text) break;
                streamingTextBuffer = text;
                const labelPrefix = '<strong>Response:</strong> ';
                const htmlText = `${labelPrefix}${escapeHtml(streamingTextBuffer)}`;
                if (!streamingMessageEl) {
                    streamingMessageEl = appendMessage('agent', streamingTextBuffer, 'Response');
                } else {
                    streamingMessageEl.innerHTML = htmlText;
                }
                break;
            }
            case 'final_audio':
                if (event.audio && event.audio.b64) {
                    const delay = Number(event.sequence || 0) === 1;
                    playAudioSegment(
                        {
                            format: event.audio.format || 'mp3',
                            chunks: [event.audio.b64],
                        },
                        delay
                    );
                }
                break;
            case 'audio_chunk': {
                const b64 = event.chunk;
                if (typeof b64 === 'string' && b64.trim()) {
                    console.log('[AUDIO] chunk recv len', b64.length, 'format', event.format || 'mp3');
                    try {
                        playAudioSegment({
                            format: event.format || 'mp3',
                            chunks: [b64],
                        });
                    } catch (err) {
                        console.warn('[AUDIO] playAudioSegment error', err);
                    }
                } else {
                    console.log('[AUDIO] chunk empty or invalid');
                }
                break;
            }
            default:
                console.log('[DEBUG] Unhandled stream event', event);
        }
    }

    function handleNonStreamingResponse(payload) {
        if (!payload || typeof payload !== 'object') {
            return;
        }
        console.log('[DEBUG] non-stream response payload', payload);
        const response = payload.response || {};
        const text = response.spokenMessage
            || response.suffixMessage
            || response.prefixMessage
            || response.followUpMessage
            || '';
        if (text) {
            appendMessage('agent', text, 'Response');
        } else {
            appendMessage('agent', 'No response text returned.', 'Response');
        }
        const audioSegments = Array.isArray(payload.audio_segments) ? payload.audio_segments : [];
        audioSegments.forEach((segment) => {
            if (segment.audio && segment.audio.b64) {
                playAudioSegment({
                    format: segment.audio.format || 'wav',
                    chunks: [segment.audio.b64],
                });
            }
        });
        if (!audioSegments.length) {
            console.warn('[AUDIO] no audio_segments returned');
        }
    }

    function escapeHtml(text) {
        const div = document.createElement('div');
        div.textContent = text;
        return div.innerHTML;
    }

    (async () => {
        const isSecureOrigin =
            window.location.protocol === 'https:' ||
            window.location.hostname === 'py-app-capture-agent-svc-dev-1-1768200251.us-east-1.elb.amazonaws.com';
        if (!isSecureOrigin) {
            updateStatus('Status: Use HTTPS or https://localhost to persist microphone permission.');
        }
        if (navigator.permissions && navigator.permissions.query) {
            try {
                const status = await navigator.permissions.query({ name: 'microphone' });
                console.log('[MIC PERMISSION]', status.state);
                if (status.state === 'denied') {
                    appendMessage(
                        'agent',
                        'Microphone access is blocked. Click the lock icon in your browser, open Site settings, and allow microphone access.',
                        'Notice'
                    );
                }
            } catch (err) {
                console.warn('Permission query failed', err);
            }
        }
    })();
</script>
</body>
</html>
