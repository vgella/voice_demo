<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Voice Agent Browser Demo</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; margin: 20px; }
    .row { display: flex; gap: 12px; flex-wrap: wrap; align-items: center; margin: 10px 0; }
    input[type="text"] { width: min(980px, 100%); padding: 10px; font-size: 14px; }
    textarea { width: min(980px, 100%); height: 110px; padding: 10px; font-size: 14px; }
    button { padding: 10px 14px; font-size: 14px; cursor: pointer; }
    .status { padding: 8px 10px; border-radius: 8px; background: #f2f2f2; display: inline-block; }
    .warn { background: #fff3cd; border: 1px solid #ffeeba; padding: 10px; border-radius: 8px; }
    pre { background: #0b1020; color: #d7e2ff; padding: 12px; border-radius: 10px; overflow: auto; }
    .card { border: 1px solid #ddd; border-radius: 12px; padding: 12px; width: min(980px, 100%); }
    .muted { color: #666; font-size: 13px; }
    label { font-weight: 600; }
  </style>
</head>
<body>
  <h2>Voice Agent Browser Demo</h2>

  <div class="card">
    <div class="row">
      <label for="voiceUrl">Voice agent URL</label>
    </div>
    <div class="row">
      <input id="voiceUrl" type="text" />
    </div>
    <div class="row muted">
      Endpoint must be <code>POST</code> and audio uses <code>multipart/form-data</code> field <code>audio</code>.
    </div>
  </div>

  <div id="secureWarn" class="warn" style="display:none; margin-top:12px;">
    <b>Mic permission warning:</b> Browsers only allow microphone recording on a <b>secure context</b>
    (HTTPS) or <b>http://localhost</b>. If you opened this as <code>file://</code> or from plain HTTP,
    the mic may be blocked.<br/>
    <span class="muted">Quick fix: run <code>python -m http.server 8000</code> in this folder and open
    <code>http://localhost:8000/index.html</code>.</span>
  </div>

  <div class="card" style="margin-top:12px;">
    <div class="row">
      <button id="startBtn">üé§ Start Listening</button>
      <button id="stopBtn" disabled>‚èπ Stop Listening</button>
      <button id="sendAudioBtn" disabled>üì§ Send Audio</button>
      <span class="status" id="status">Status: Idle</span>
    </div>

    <div class="row">
      <label for="typedMsg">...or type your question here</label>
    </div>
    <div class="row">
      <textarea id="typedMsg" placeholder="Type a message and click Send Typed Message"></textarea>
    </div>
    <div class="row">
      <button id="sendTypedBtn">Send Typed Message</button>
    </div>

    <div class="row muted">
      Optional IDs (recommended stable per session): user_id / thread_id / rooftop_id
    </div>
    <div class="row">
      <input id="userId" type="text" placeholder="user_id (optional)" />
      <input id="threadId" type="text" placeholder="thread_id (optional)" />
      <input id="rooftopId" type="text" placeholder="rooftop_id (optional, default 6)" />
    </div>
  </div>

  <div class="card" style="margin-top:12px;">
    <h3 style="margin-top:0;">Conversation</h3>
    <div id="log"></div>
  </div>

  <div class="card" style="margin-top:12px;">
    <h3 style="margin-top:0;">Raw response (debug)</h3>
    <pre id="raw">(none yet)</pre>
  </div>

<script>
(() => {
  // MUST be set to the :5000 endpoint you provided
  const DEFAULT_VOICE_URL = "http://py-app-capture-agent-svc-dev-1-1768200251.us-east-1.elb.amazonaws.com:5000/voice/conversation";

  const voiceUrlEl = document.getElementById("voiceUrl");
  const startBtn = document.getElementById("startBtn");
  const stopBtn = document.getElementById("stopBtn");
  const sendAudioBtn = document.getElementById("sendAudioBtn");
  const sendTypedBtn = document.getElementById("sendTypedBtn");
  const statusEl = document.getElementById("status");
  const rawEl = document.getElementById("raw");
  const logEl = document.getElementById("log");

  const typedMsgEl = document.getElementById("typedMsg");
  const userIdEl = document.getElementById("userId");
  const threadIdEl = document.getElementById("threadId");
  const rooftopIdEl = document.getElementById("rooftopId");

  voiceUrlEl.value = DEFAULT_VOICE_URL;

  // Secure context check for mic
  const isSecureOrigin =
    window.location.protocol === "https:" ||
    window.location.hostname === "localhost" ||
    window.location.hostname === "127.0.0.1";
  if (!isSecureOrigin) {
    document.getElementById("secureWarn").style.display = "block";
  }

  let mediaRecorder = null;
  let audioChunks = [];
  let lastAudioBlob = null;

  function setStatus(msg) {
    statusEl.textContent = "Status: " + msg;
  }

  function escapeHtml(s) {
    return (s || "").replace(/[&<>"']/g, c => ({
      "&":"&amp;","<":"&lt;",">":"&gt;",'"':"&quot;","'":"&#39;"
    }[c]));
  }

  function addLogCard(title, bodyHtml) {
    const div = document.createElement("div");
    div.style.borderTop = "1px solid #eee";
    div.style.padding = "10px 0";
    div.innerHTML = `<div><b>${escapeHtml(title)}</b></div><div style="margin-top:6px;">${bodyHtml}</div>`;
    logEl.prepend(div);
  }

  async function playAudioSegments(segments) {
    if (!Array.isArray(segments) || segments.length === 0) return;

    // sort by sequence, then play one-by-one
    const sorted = [...segments].sort((a,b) => (a.sequence ?? 0) - (b.sequence ?? 0));

    for (const seg of sorted) {
      const b64 = seg?.audio?.b64;
      if (!b64) continue;

      const wavBytes = Uint8Array.from(atob(b64), c => c.charCodeAt(0));
      const blob = new Blob([wavBytes], { type: "audio/wav" });
      const url = URL.createObjectURL(blob);

      await new Promise((resolve) => {
        const audio = new Audio(url);
        audio.onended = () => { URL.revokeObjectURL(url); resolve(); };
        audio.onerror = () => { URL.revokeObjectURL(url); resolve(); };
        audio.play().catch(() => { URL.revokeObjectURL(url); resolve(); });
      });
    }
  }

  function buildOptionalFields(formOrObj) {
    const user_id = userIdEl.value.trim();
    const thread_id = threadIdEl.value.trim();
    const rooftop_id = rooftopIdEl.value.trim();

    // If it's FormData
    if (formOrObj instanceof FormData) {
      if (user_id) formOrObj.append("user_id", user_id);
      if (thread_id) formOrObj.append("thread_id", thread_id);
      if (rooftop_id) formOrObj.append("rooftop_id", rooftop_id);
    } else {
      if (user_id) formOrObj.user_id = user_id;
      if (thread_id) formOrObj.thread_id = thread_id;
      if (rooftop_id) formOrObj.rooftop_id = rooftop_id;
    }
  }

  async function sendAudio(blob) {
    const url = voiceUrlEl.value.trim();
    if (!url) return;

    setStatus("Uploading audio‚Ä¶");

    const form = new FormData();
    // Backend expects field name "audio"
    form.append("audio", blob, "recording.webm");
    buildOptionalFields(form);

    const res = await fetch(url, { method: "POST", body: form });
    const text = await res.text();

    if (!res.ok) {
      setStatus(`Error - HTTP ${res.status}`);
      addLogCard("Server error", `<pre>${escapeHtml(text)}</pre>`);
      rawEl.textContent = text;
      return;
    }

    let data;
    try { data = JSON.parse(text); }
    catch {
      setStatus("Error - Non-JSON response");
      addLogCard("Non-JSON response", `<pre>${escapeHtml(text)}</pre>`);
      rawEl.textContent = text;
      return;
    }

    rawEl.textContent = JSON.stringify(data, null, 2);

    // Render transcript + combined spoken response
    const transcript = data.transcript ? `<div><b>Transcript:</b> ${escapeHtml(data.transcript)}</div>` : "";
    const r = data.response || {};
    const spoken = [r.prefixMessage, r.suffixMessage, r.followUpMessage].filter(Boolean).join(" ").trim();
    const vins = Array.isArray(r.vins) ? r.vins : [];
    const vinsHtml = vins.length ? `<div class="muted">VINs: ${escapeHtml(vins.join(", "))}</div>` : "";

    addLogCard(
      "Audio ‚Üí Response",
      `${transcript}<div style="margin-top:6px;">${escapeHtml(spoken || "(empty response)")}</div>${vinsHtml}`
    );

    // Play returned TTS audio segments if present
    if (Array.isArray(data.audio_segments) && data.audio_segments.length) {
      setStatus("Playing response audio‚Ä¶");
      await playAudioSegments(data.audio_segments);
      setStatus("Done");
    } else {
      setStatus("Done (no audio_segments returned)");
    }
  }

  async function sendTypedMessage() {
    const url = voiceUrlEl.value.trim();
    const message = typedMsgEl.value.trim();
    if (!url) return;
    if (!message) {
      addLogCard("Client", "<i>Please type a message first.</i>");
      return;
    }

    setStatus("Sending typed message‚Ä¶");

    const payload = { message };
    buildOptionalFields(payload);
    if (!payload.rooftop_id) payload.rooftop_id = "6";

    const res = await fetch(url, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(payload),
    });

    const text = await res.text();

    if (!res.ok) {
      setStatus(`Error - HTTP ${res.status}`);
      addLogCard("Server error", `<pre>${escapeHtml(text)}</pre>`);
      rawEl.textContent = text;
      return;
    }

    let data;
    try { data = JSON.parse(text); }
    catch {
      setStatus("Error - Non-JSON response");
      addLogCard("Non-JSON response", `<pre>${escapeHtml(text)}</pre>`);
      rawEl.textContent = text;
      return;
    }

    rawEl.textContent = JSON.stringify(data, null, 2);

    const r = data.response || {};
    const spoken = [r.prefixMessage, r.suffixMessage, r.followUpMessage].filter(Boolean).join(" ").trim();
    const vins = Array.isArray(r.vins) ? r.vins : [];

    addLogCard(
      "Text ‚Üí Response",
      `<div><b>You:</b> ${escapeHtml(message)}</div>
       <div style="margin-top:6px;"><b>Agent:</b> ${escapeHtml(spoken || "(empty response)")}</div>
       ${vins.length ? `<div class="muted">VINs: ${escapeHtml(vins.join(", "))}</div>` : ""}`
    );

    // Some servers may still return audio_segments even for text input. If present, play them.
    if (Array.isArray(data.audio_segments) && data.audio_segments.length) {
      setStatus("Playing response audio‚Ä¶");
      await playAudioSegments(data.audio_segments);
      setStatus("Done");
    } else {
      setStatus("Done");
    }
  }

  startBtn.addEventListener("click", async () => {
    audioChunks = [];
    lastAudioBlob = null;

    try {
      setStatus("Requesting microphone permission‚Ä¶");

      // Prefer audio/webm. If unsupported, MediaRecorder may still work with browser defaults.
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      const options = {};
      if (MediaRecorder.isTypeSupported("audio/webm")) {
        options.mimeType = "audio/webm";
      }

      mediaRecorder = new MediaRecorder(stream, options);
      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) audioChunks.push(e.data);
      };
      mediaRecorder.onstop = () => {
        // Stop tracks so mic isn‚Äôt held open
        stream.getTracks().forEach(t => t.stop());
        lastAudioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType || "audio/webm" });
        sendAudioBtn.disabled = !lastAudioBlob;
        setStatus(lastAudioBlob ? `Recorded (${Math.round(lastAudioBlob.size/1024)} KB). Ready to send.` : "No audio captured.");
      };

      mediaRecorder.start();
      startBtn.disabled = true;
      stopBtn.disabled = false;
      sendAudioBtn.disabled = true;
      setStatus("Recording‚Ä¶");
    } catch (err) {
      setStatus("Mic error");
      addLogCard("Microphone error", `<pre>${escapeHtml(String(err))}</pre>`);
    }
  });

  stopBtn.addEventListener("click", () => {
    if (!mediaRecorder) return;
    stopBtn.disabled = true;
    setStatus("Stopping‚Ä¶");
    mediaRecorder.stop();
    startBtn.disabled = false;
  });

  sendAudioBtn.addEventListener("click", async () => {
    if (!lastAudioBlob) return;
    sendAudioBtn.disabled = true;
    await sendAudio(lastAudioBlob);
  });

  sendTypedBtn.addEventListener("click", async () => {
    await sendTypedMessage();
  });
})();
</script>
</body>
</html>
